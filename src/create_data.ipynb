{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net loaded\n"
     ]
    }
   ],
   "source": [
    "import sys,os,time,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ops\n",
    "from resnet_tsm import resnet18 as resnet\n",
    "from utils import get_dtstr, emo2txt, imread_to_rgb, crop_img\n",
    "import face_recognition\n",
    "import moviepy.editor as mpe\n",
    "\n",
    "# restore net\n",
    "net = resnet().cuda()\n",
    "ckpt = torch.load(ops.weight_path+'/resnet18_tsm_weights.tar')\n",
    "net.load_state_dict(ckpt['model_state_dict'])\n",
    "net.eval()\n",
    "print 'net loaded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_path\n",
    "# DB_PATH = '/home/jhchoi/datasets2/friends/'\n",
    "epi_sel = 'ep06'\n",
    "DB_PATH = '../../img_ep06/'\n",
    "\n",
    "# output path\n",
    "OUT_PATH = '../data/friends_s01_'+epi_sel+'.jsonl'\n",
    "out_json = open(OUT_PATH, 'w+')\n",
    "\n",
    "import json\n",
    "\n",
    "ep06_track = sorted(os.listdir('../../anno_ep06/'))\n",
    "ep06_dict = dict()\n",
    "for i,f in enumerate(ep06_track):\n",
    "    with open('../../anno_ep06/'+f) as jsf:\n",
    "        js = json.load(jsf)\n",
    "        ep06_dict[i] = js\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6038/6237"
     ]
    }
   ],
   "source": [
    "for i,imf in enumerate(sorted(os.listdir(DB_PATH))):\n",
    "    sys.stdout.write(\"\\r\"+str(i)+'/'+str(len(os.listdir(DB_PATH))))\n",
    "    f_b_size = 4      # buffer size\n",
    "    \n",
    "    id_dict = ep06_dict[i]\n",
    "    \n",
    "    # new frame buffer\n",
    "    f_buffer = []\n",
    "    for j in range(f_b_size):\n",
    "        f_fname = imf #str('%05d'%(i-f_b_size+j+1))+'.jpg'\n",
    "        f_img = imread_to_rgb(os.path.join(DB_PATH, f_fname))\n",
    "        f_buffer.append(f_img)\n",
    "    \n",
    "    # === process buffer\n",
    "    for j in range(len(id_dict)):\n",
    "        # crop person region coor=(xmin,ymin,xmax,ymax)\n",
    "#         obj_coor = np.array([id_dict[j]['topleft']['x'],id_dict[j]['topleft']['y'], \n",
    "#                              id_dict[j]['bottomright']['x'],id_dict[j]['bottomright']['y'] ]).astype(int)\n",
    "        obj_coor = np.array([id_dict[j]['bottomright']['x'],id_dict[j]['bottomright']['y'], \n",
    "                             id_dict[j]['topleft']['x'],id_dict[j]['topleft']['y'] ]).astype(int)\n",
    "    \n",
    "        obj_crop = crop_img(f_buffer[-1], obj_coor[0], obj_coor[1], obj_coor[2]-obj_coor[0], obj_coor[3]-obj_coor[1])\n",
    "        obj_id = int(id_dict[j]['id'])\n",
    "        # detect faces\n",
    "        faces_coor = np.array(face_recognition.face_locations((obj_crop*255).astype(np.uint8))).astype(int)\n",
    "        if faces_coor.ndim < 2:\n",
    "            # no face, continue\n",
    "            continue\n",
    "        else:\n",
    "            num_faces = faces_coor.shape[0]\n",
    "        # refine coordinates as (xmin,ymin,xmax,ymax)\n",
    "        faces_coor = faces_coor[0]\n",
    "        faces_coor = np.array([faces_coor[3], faces_coor[0], faces_coor[1], faces_coor[2]])\n",
    "        faces_coor[0] += obj_coor[0]\n",
    "        faces_coor[1] += obj_coor[1]\n",
    "        faces_coor[2] += obj_coor[0]\n",
    "        faces_coor[3] += obj_coor[1]\n",
    "\n",
    "        # extract faces and get emotions\n",
    "        # get face crops from buffer\n",
    "        coor = faces_coor #faces_coor[:,j]\n",
    "        w = coor[2] - coor[0]\n",
    "        h = coor[3] - coor[1]\n",
    "        m = 0.5\n",
    "        s = np.sqrt((w+(w+h)*m)*(h+(w+h)*m))\n",
    "\n",
    "        f_crops = [crop_img(im, int(coor[0]+w*0.5), int(coor[1]+h*0.5), int(s), int(s), True) for im in f_buffer]\n",
    "        f_batch = [cv2.resize(f_c, (224,224)) for f_c in f_crops]\n",
    "        #plt.imsave('../../img_crop_ep06/'+str('%05d'%i)+'_'+str(j)+'.jpg', f_batch[0])\n",
    "        # net forward - get emotion\n",
    "        f_batch = torch.Tensor(np.array(f_batch)).cuda()\n",
    "        f_batch = f_batch.unsqueeze(0).permute(0,1,4,2,3)\n",
    "        with torch.no_grad():\n",
    "            f_emo = net(f_batch)[0,-2:,:].mean(0).argmax().detach().cpu().numpy()\n",
    "        # write text\n",
    "        f_emo_txt =  emo2txt(f_emo)\n",
    "        json_txt = str('{\"type\": \"emotion\", \"class\": \"%s\", \"frames\": %d, \"coordinates\": [%d,%d,%d,%d], \"id\": %d}\\n'%\\\n",
    "                       (f_emo_txt, i, coor[0],coor[1],coor[2],coor[3], obj_id))\n",
    "        out_json.write(json_txt)\n",
    "\n",
    "out_json.close()\n",
    "#float(i-1)*29907/6237.*1/23.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
