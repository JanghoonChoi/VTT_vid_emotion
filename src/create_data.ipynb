{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,time,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ops\n",
    "from resnet_tsm import resnet18 as resnet\n",
    "from utils import get_dtstr, emo2txt, imread_to_rgb, crop_img\n",
    "import face_recognition\n",
    "import moviepy.editor as mpe\n",
    "\n",
    "# restore net\n",
    "net = resnet().cuda()\n",
    "ckpt = torch.load(ops.weight_path+'/resnet18_tsm_weights.tar')\n",
    "net.load_state_dict(ckpt['model_state_dict'])\n",
    "net.eval()\n",
    "\n",
    "# episode_path\n",
    "DB_PATH = '/home/jhchoi/datasets2/friends/'\n",
    "epi_sel = 'ep06'\n",
    "\n",
    "# output path\n",
    "OUT_PATH = '../data/friends_s01_'+epi_sel+'.jsonl'\n",
    "out_json = open(OUT_PATH, 'w+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29905/29907"
     ]
    }
   ],
   "source": [
    "num_f = len(os.listdir(os.path.join(DB_PATH, epi_sel)))\n",
    "\n",
    "f_b_size = 4      # buffer size\n",
    "f_interval = 5    # frame interval\n",
    "\n",
    "for i in range(0, num_f, f_interval):\n",
    "    sys.stdout.write(\"\\r\"+str(i)+'/'+str(num_f))\n",
    "    \n",
    "    # skip frame #0\n",
    "    if i==0:\n",
    "        continue\n",
    "    \n",
    "    # new frame buffer\n",
    "    f_buffer = []\n",
    "    for j in range(f_b_size):\n",
    "        f_fname = str('%05d'%(i-f_b_size+j+1))+'.jpg'\n",
    "        f_img = imread_to_rgb(os.path.join(DB_PATH, epi_sel, f_fname))\n",
    "        f_buffer.append(f_img)\n",
    "    \n",
    "    # === process buffer\n",
    "    # detect faces\n",
    "    faces_coor = np.array(face_recognition.face_locations((f_buffer[-1]*255).astype(np.uint8))).astype(int)\n",
    "    if faces_coor.ndim < 2:\n",
    "        # no face, continue\n",
    "        continue\n",
    "    else:\n",
    "        num_faces = faces_coor.shape[0]\n",
    "    # refine coordinates as (xmin,ymin,xmax,ymax)\n",
    "    faces_coor = np.array([faces_coor[:,3], faces_coor[:,0], faces_coor[:,1], faces_coor[:,2]])\n",
    "\n",
    "    # extract faces and get emotions\n",
    "    for j in range(num_faces):\n",
    "        # get face crops from buffer\n",
    "        coor = faces_coor[:,j]\n",
    "        w = coor[2] - coor[0]\n",
    "        h = coor[3] - coor[1]\n",
    "        m = 0.5\n",
    "        s = np.sqrt((w+(w+h)*m)*(h+(w+h)*m))\n",
    "\n",
    "        f_crops = [crop_img(im, int(coor[0]+w*0.5), int(coor[1]+h*0.5), int(s), int(s), True) for im in f_buffer]\n",
    "        f_batch = [cv2.resize(f_c, (224,224)) for f_c in f_crops]\n",
    "        # net forward - get emotion\n",
    "        f_batch = torch.Tensor(np.array(f_batch)).cuda()\n",
    "        f_batch = f_batch.unsqueeze(0).permute(0,1,4,2,3)\n",
    "        with torch.no_grad():\n",
    "            f_emo = net(f_batch)[0,-2:,:].mean(0).argmax().detach().cpu().numpy()\n",
    "        # write text\n",
    "        f_emo_txt =  emo2txt(f_emo)\n",
    "        json_txt = str('{\"type\": \"emotion\", \"class\": \"%s\", \"seconds\": %.3f, \"coordinates\": [%d,%d,%d,%d], \"object\": \"%d\"}\\n'%\\\n",
    "                       (f_emo_txt, float(i)/24., coor[0],coor[1],coor[2],coor[3], j))\n",
    "        out_json.write(json_txt)\n",
    "\n",
    "out_json.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
