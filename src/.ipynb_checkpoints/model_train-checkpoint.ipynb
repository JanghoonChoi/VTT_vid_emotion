{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,time,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import ops, loss_def\n",
    "from resnet import resnet50\n",
    "from batch_AffectNet import AffectNet_dataset\n",
    "from batch_Friends import Friends_dataset\n",
    "from utils import get_dtstr\n",
    "\n",
    "if not ops.do_train:\n",
    "    print 'not in training mode, exit'\n",
    "    sys.exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training from scratch...\n"
     ]
    }
   ],
   "source": [
    "# define dataloader\n",
    "affectnet_dataset = AffectNet_dataset(ops.af_dict, ops)\n",
    "affectnet_loader = DataLoader(dataset=affectnet_dataset, batch_size=ops.batch_size, num_workers=4)\n",
    "\n",
    "# define resent\n",
    "net = resnet50().cuda()\n",
    "\n",
    "# define optim\n",
    "optim = torch.optim.Adam(net.parameters(), lr=ops.learning_rate, weight_decay=ops.w_decay, amsgrad=True)\n",
    "\n",
    "# restore chkpt\n",
    "if ops.from_chkpt:\n",
    "    chkpt_file = sorted(os.listdir(ops.chkpt_path))[-1]\n",
    "    \n",
    "    if chkpt_file:\n",
    "        ckpt = torch.load(ops.chkpt_path+chkpt_file)\n",
    "        resume_step = ckpt['step']\n",
    "        today_dt = ckpt['logdt']\n",
    "        net.load_state_dict(ckpt['model_state_dict'])\n",
    "        optim.load_state_dict(ckpt['optim_state_dict'])\n",
    "        \n",
    "    else:\n",
    "        os.error('no checkpoint')\n",
    "\n",
    "    print 'continue from checkpoint: ',\n",
    "    print chkpt_file\n",
    "else:\n",
    "    print 'start training from scratch...'\n",
    "    resume_step = 0\n",
    "    # init text file\n",
    "    today_dt = str(time.strftime(\"%m-%d-%H-%M\", time.gmtime()))\n",
    "    output_text = open(\"err_logs/log_\"+ today_dt + \".txt\",\"w\")\n",
    "    output_text.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load valid set...\n",
      "> complete\n"
     ]
    }
   ],
   "source": [
    "# gen valid set\n",
    "if ops.make_valid:\n",
    "    print 'generate new valid set...'\n",
    "    friends_dataset = Friends_dataset(ops.fr_dict, ops)\n",
    "    friends_loader = DataLoader(dataset=friends_dataset, batch_size=ops.batch_size, num_workers=4)\n",
    "    \n",
    "    val_img = []\n",
    "    val_emo = []\n",
    "    \n",
    "    for i, bat in enumerate(friends_loader):\n",
    "        sys.stdout.write(\"\\r\"+str(i+1)+'/'+str(ops.valid_size//ops.batch_size))\n",
    "        bat_img = bat[0].numpy()\n",
    "        bat_emo = bat[1].numpy()\n",
    "        val_img.append(bat_img)\n",
    "        val_emo.append(bat_emo)\n",
    "        \n",
    "    val_img = np.array(val_img)\n",
    "    val_emo = np.array(val_emo)\n",
    "    \n",
    "    print 'saving valid set...'\n",
    "    np.savez('../../dicts/friends_valid.npz', val_img=val_img, val_emo=val_emo)\n",
    "    print '\\n saved valid set, exiting'\n",
    "    sys.exit()\n",
    "\n",
    "else:\n",
    "    print 'load valid set...'\n",
    "    valid_npz = np.load('../../dicts/friends_valid.npz', allow_pickle=True)\n",
    "    val_img = valid_npz['val_img']\n",
    "    val_emo = valid_npz['val_emo']\n",
    "\n",
    "print '> complete'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 elaptime: 13.275967\n",
      " valerror: 1.310124446630478\n",
      " accurate: 0.0\n",
      "step:0, error: 1.2928957\n",
      "  lr: 0.0001, elaptime: 0.779858, 0.103068\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_dtstr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3b36772ff9a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m             torch.save({'step' : step, 'logdt' : today_dt,\n\u001b[1;32m     83\u001b[0m                         \u001b[0;34m'model_state_dict'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optim_state_dict'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                         }, ops.chkpt_path+'chkpt_'+get_dtstr()+'_'+str(step)+'.tar')\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"saved chkpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_dtstr' is not defined"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "for epoch in range(ops.epoc_step):\n",
    "    for i, bat in enumerate(affectnet_loader, 0):\n",
    "        step = resume_step + epoch*ops.iter_step + i\n",
    "\n",
    "        # bat = (img, emo)\n",
    "        bat_img = bat[0].cuda()\n",
    "        bat_emo = bat[1].cuda()\n",
    "        toc0 = time.time() - tic\n",
    "\n",
    "        # fit using batch data\n",
    "        tic = time.time()\n",
    "        # batch forward\n",
    "        net.train()\n",
    "        bat_prd = net.forward(bat_img)\n",
    "        # get loss\n",
    "        loss = loss_def.loss_total(bat_emo, bat_prd, ops.loss_lambda)\n",
    "        \n",
    "        # optim step\n",
    "        learning_rate_use = ops.learning_rate\n",
    "        optim.param_groups[0]['lr'] = learning_rate_use\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        toc1 = time.time() - tic\n",
    "        \n",
    "        # validation step\n",
    "        if step % ops.vald_step == 0:\n",
    "            # eval mode\n",
    "            net.eval()\n",
    "            val_times = int(ops.valid_size/ops.batch_size)\n",
    "            valid_all = np.zeros(val_times)\n",
    "            v_acc_all = np.zeros(val_times)\n",
    "\n",
    "            tic = time.time()\n",
    "            for val_i in range(val_times):\n",
    "                sys.stdout.write(\"\\r\"+str(val_i+1)+'/'+str(val_times))\n",
    "                # get i-th batch from valid set\n",
    "                val_i_img = torch.Tensor(val_img[val_i]).cuda()\n",
    "                val_i_emo = torch.Tensor(val_emo[val_i]).cuda()\n",
    "                # forward \n",
    "                val_i_prd = net.forward(val_i_img)\n",
    "                # total loss/err \n",
    "                val_i_err = loss_def.loss_total(val_i_emo, val_i_prd, ops.loss_lambda)\n",
    "                # cumulate errors\n",
    "                valid_all[val_i] = val_i_err.detach().cpu().numpy()\n",
    "\n",
    "                # cumulate accuracy\n",
    "                val_i_emo_am = val_i_emo.argmax(dim=1)\n",
    "                val_i_prd_am = val_i_prd.argmax(dim=1)\n",
    "                val_i_acc = torch.sum(val_i_emo_am == val_i_prd_am) / float(ops.batch_size)\n",
    "                v_acc_all[val_i] = val_i_acc.detach().cpu().numpy()\n",
    "\n",
    "            toc2 = time.time() - tic\n",
    "            print \" elaptime: \" + str('%.6f'%toc2)\n",
    "            print \" valerror: \" + str(valid_all.mean())\n",
    "            print \" accurate: \" + str(v_acc_all.mean())\n",
    "\n",
    "        # error step\n",
    "        if step % ops.errd_step == 0:\n",
    "            net.eval()\n",
    "            bat_prd = net.forward(bat_img)\n",
    "            loss = loss_def.loss_total(bat_emo, bat_prd, ops.loss_lambda)\n",
    "            error = loss.detach().cpu().numpy()\n",
    "\n",
    "            print \"step:\" + str(step) + ', error: ' + str(error)\n",
    "            print '  lr: ' + str(learning_rate_use) + ', elaptime: ' + str('%.6f'%toc0) + ', ' + str('%.6f'%toc1)\n",
    "\n",
    "            # open - write - close\n",
    "            output_text = open(\"err_logs/log_\"+ today_dt + \".txt\",\"a\")\n",
    "            output_text.write(\"%s, %s, %s, %s\\n\" % (step, error, valid_all.mean(), v_acc_all.mean()))\n",
    "            output_text.close()\n",
    "            net.train()\n",
    "\n",
    "        # save step\n",
    "        if step % ops.save_step == 0:\n",
    "            # remove oldest\n",
    "            ckpt_nums = len(sorted(os.listdir(ops.chkpt_path)))\n",
    "            if ckpt_nums == ops.maxn_chkpt:\n",
    "                os.remove(ops.chkpt_path+'/'+sorted(os.listdir(ops.chkpt_path))[0])\n",
    "            # save new\n",
    "            torch.save({'step' : step, 'logdt' : today_dt,\n",
    "                        'model_state_dict' : net.state_dict(), 'optim_state_dict' : optim.state_dict()\n",
    "                        }, ops.chkpt_path+'chkpt_'+get_dtstr()+'_'+str(step)+'.tar')\n",
    "            print \"saved chkpt\"\n",
    "            \n",
    "        tic = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
